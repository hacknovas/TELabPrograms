{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d25e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e34acbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1576a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word:  ['Sachin', 'is', 'considered', 'to', 'be', 'one', 'of', 'the', 'greatest', 'cricket', 'players', '.', 'Virat', 'is', 'the', 'captain', 'of', 'the', 'Indian', 'cricket', 'team']\n",
      "\n",
      "Sentence:  ['Sachin is considered to be one of the greatest cricket players.', 'Virat is the captain of the Indian cricket team']\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize,word_tokenize\n",
    "\n",
    "sentence=\"Sachin is considered to be one of the greatest cricket players. Virat is the captain of the Indian cricket team\"\n",
    "\n",
    "print(\"\\nWord: \",word_tokenize(sentence))\n",
    "print(\"\\nSentence: \",sent_tokenize(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9e3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6631680d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_word=stopwords.words(\"English\")\n",
    "stop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ec096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f6d6777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the unclean version :  ['Sachin', 'is', 'considered', 'to', 'be', 'one', 'of', 'the', 'greatest', 'cricket', 'players', '.', 'Virat', 'is', 'the', 'captain', 'of', 'the', 'Indian', 'cricket', 'team']\n",
      "\n",
      "This is the cleaned version :  ['Sachin', 'considered', 'one', 'greatest', 'cricket', 'players', '.', 'Virat', 'captain', 'Indian', 'cricket', 'team']\n"
     ]
    }
   ],
   "source": [
    "word_token=word_tokenize(sentence)\n",
    "cleaned_token=[]\n",
    "\n",
    "for word in word_token:\n",
    "    if word not in stop_word:\n",
    "        cleaned_token.append(word)\n",
    "        \n",
    "\n",
    "print(\"\\nThis is the unclean version : \",word_token)\n",
    "print(\"\\nThis is the cleaned version : \",cleaned_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd452a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[cleaned_token.lower() for cleaned_token in cleaned_token if cleaned_token.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb11748a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sachin',\n",
       " 'considered',\n",
       " 'one',\n",
       " 'greatest',\n",
       " 'cricket',\n",
       " 'players',\n",
       " 'virat',\n",
       " 'captain',\n",
       " 'indian',\n",
       " 'cricket',\n",
       " 'team']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee2d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92aebb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sachin',\n",
       " 'consid',\n",
       " 'one',\n",
       " 'greatest',\n",
       " 'cricket',\n",
       " 'player',\n",
       " 'virat',\n",
       " 'captain',\n",
       " 'indian',\n",
       " 'cricket',\n",
       " 'team']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "Stemmer_out=[stemmer.stem(words) for words in words]\n",
    "\n",
    "Stemmer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56727a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "421b4c5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sachin',\n",
       " 'considered',\n",
       " 'one',\n",
       " 'greatest',\n",
       " 'cricket',\n",
       " 'player',\n",
       " 'virat',\n",
       " 'captain',\n",
       " 'indian',\n",
       " 'cricket',\n",
       " 'team']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lemmitizer=WordNetLemmatizer()\n",
    "Lemmitizer_out=[Lemmitizer.lemmatize(words) for words in words]\n",
    "\n",
    "Lemmitizer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d1a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83f6dd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sachin', 'NN'),\n",
       " ('considered', 'VBD'),\n",
       " ('one', 'CD'),\n",
       " ('greatest', 'JJS'),\n",
       " ('cricket', 'NN'),\n",
       " ('player', 'NN'),\n",
       " ('virat', 'NN'),\n",
       " ('captain', 'NN'),\n",
       " ('indian', 'JJ'),\n",
       " ('cricket', 'NN'),\n",
       " ('team', 'NN')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "tagging=pos_tag(Lemmitizer_out)\n",
    "tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf40cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc09e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['the cat see the mouse',\n",
    "      'the house has a tiny little mouse',\n",
    "       'the mouse ran away from the house',\n",
    "        'the cat finally ate the mouse',\n",
    "       'the end of the mouse story'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57749a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ate</th>\n",
       "      <th>away</th>\n",
       "      <th>cat</th>\n",
       "      <th>end</th>\n",
       "      <th>finally</th>\n",
       "      <th>from</th>\n",
       "      <th>has</th>\n",
       "      <th>house</th>\n",
       "      <th>little</th>\n",
       "      <th>mouse</th>\n",
       "      <th>of</th>\n",
       "      <th>ran</th>\n",
       "      <th>see</th>\n",
       "      <th>story</th>\n",
       "      <th>the</th>\n",
       "      <th>tiny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ate  away  cat  end  finally  from  has  house  little  mouse  of  ran   \n",
       "0    0     0    1    0        0     0    0      0       0      1   0    0  \\\n",
       "1    0     0    0    0        0     0    1      1       1      1   0    0   \n",
       "2    0     1    0    0        0     1    0      1       0      1   0    1   \n",
       "3    1     0    1    0        1     0    0      0       0      1   0    0   \n",
       "4    0     0    0    1        0     0    0      0       0      1   1    0   \n",
       "\n",
       "   see  story  the  tiny  \n",
       "0    1      0    2     0  \n",
       "1    0      0    1     1  \n",
       "2    0      0    2     0  \n",
       "3    0      0    2     0  \n",
       "4    0      1    2     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "\n",
    "cv=CountVectorizer()\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "\n",
    "tf=pd.DataFrame(word_count_vector.toarray(),columns=cv.get_feature_names_out())\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d5dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d093e85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>IDF Weaiht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ate</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>away</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>end</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finally</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>from</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>has</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>house</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>little</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mouse</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>of</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ran</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>see</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>story</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tiny</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature Name  IDF Weaiht\n",
       "0           ate    2.098612\n",
       "1          away    2.098612\n",
       "2           cat    1.693147\n",
       "3           end    2.098612\n",
       "4       finally    2.098612\n",
       "5          from    2.098612\n",
       "6           has    2.098612\n",
       "7         house    1.693147\n",
       "8        little    2.098612\n",
       "9         mouse    1.000000\n",
       "10           of    2.098612\n",
       "11          ran    2.098612\n",
       "12          see    2.098612\n",
       "13        story    2.098612\n",
       "14          the    1.000000\n",
       "15         tiny    2.098612"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidft=TfidfTransformer()\n",
    "\n",
    "X=tfidft.fit_transform(word_count_vector)\n",
    "\n",
    "idf=pd.DataFrame({\"Feature Name\":cv.get_feature_names(),\"IDF Weaiht\":tfidft.idf_})\n",
    "\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092a31c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81e4e3cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ate</th>\n",
       "      <th>away</th>\n",
       "      <th>cat</th>\n",
       "      <th>end</th>\n",
       "      <th>finally</th>\n",
       "      <th>from</th>\n",
       "      <th>has</th>\n",
       "      <th>house</th>\n",
       "      <th>little</th>\n",
       "      <th>mouse</th>\n",
       "      <th>of</th>\n",
       "      <th>ran</th>\n",
       "      <th>see</th>\n",
       "      <th>story</th>\n",
       "      <th>the</th>\n",
       "      <th>tiny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570941</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.398203</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.235185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235185</td>\n",
       "      <td>0.493562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.368780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435614</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.513923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489774</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.491753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234323</td>\n",
       "      <td>0.491753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.491753</td>\n",
       "      <td>0.468646</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ate      away       cat       end   finally      from       has   \n",
       "0  0.000000  0.000000  0.483344  0.000000  0.000000  0.000000  0.000000  \\\n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.493562   \n",
       "2  0.000000  0.457093  0.000000  0.000000  0.000000  0.457093  0.000000   \n",
       "3  0.513923  0.000000  0.414630  0.000000  0.513923  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.491753  0.000000  0.000000  0.000000   \n",
       "\n",
       "      house    little     mouse        of       ran       see     story   \n",
       "0  0.000000  0.000000  0.285471  0.000000  0.000000  0.599092  0.000000  \\\n",
       "1  0.398203  0.493562  0.235185  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.368780  0.000000  0.217807  0.000000  0.457093  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.244887  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.234323  0.491753  0.000000  0.000000  0.491753   \n",
       "\n",
       "        the      tiny  \n",
       "0  0.570941  0.000000  \n",
       "1  0.235185  0.493562  \n",
       "2  0.435614  0.000000  \n",
       "3  0.489774  0.000000  \n",
       "4  0.468646  0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = pd.DataFrame(X.toarray() ,columns=cv.get_feature_names())\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7977ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6247f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef320ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000fc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36503d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb4239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a410abf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ace82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5241d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e89e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5542a05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4bbcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611952a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7282fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"My self Doni Prathamesh from pune. i was good at programming but now i am not at expert level since last two months.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dfb4c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['My',\n",
       "  'self',\n",
       "  'Doni',\n",
       "  'Prathamesh',\n",
       "  'from',\n",
       "  'pune',\n",
       "  '.',\n",
       "  'i',\n",
       "  'was',\n",
       "  'good',\n",
       "  'at',\n",
       "  'programming',\n",
       "  'but',\n",
       "  'now',\n",
       "  'i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'at',\n",
       "  'expert',\n",
       "  'level',\n",
       "  'since',\n",
       "  'last',\n",
       "  'two',\n",
       "  'months',\n",
       "  '.'],\n",
       " ['My self Doni Prathamesh from pune.',\n",
       "  'i was good at programming but now i am not at expert level since last two months.'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize,sent_tokenize,pos_tag\n",
    "\n",
    "word_tokens=word_tokenize(sentence)\n",
    "sentence_tokens=sent_tokenize(sentence)\n",
    "\n",
    "word_tokens,sentence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e4b082d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_word=stopwords.words(\"english\")\n",
    "stop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9d2bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'self',\n",
       " 'Doni',\n",
       " 'Prathamesh',\n",
       " 'pune',\n",
       " '.',\n",
       " 'good',\n",
       " 'programming',\n",
       " 'expert',\n",
       " 'level',\n",
       " 'since',\n",
       " 'last',\n",
       " 'two',\n",
       " 'months',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_stop=[]\n",
    "\n",
    "for word in word_tokens:\n",
    "    if word not in stop_word:\n",
    "        without_stop.append(word)\n",
    "        \n",
    "without_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e509000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07cdcdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'self',\n",
       " 'doni',\n",
       " 'prathamesh',\n",
       " 'pune',\n",
       " 'good',\n",
       " 'programming',\n",
       " 'expert',\n",
       " 'level',\n",
       " 'since',\n",
       " 'last',\n",
       " 'two',\n",
       " 'months']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[without_stop.lower() for without_stop in without_stop if without_stop.isalpha()]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a674890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02da69f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'self',\n",
       " 'doni',\n",
       " 'prathamesh',\n",
       " 'pune',\n",
       " 'good',\n",
       " 'program',\n",
       " 'expert',\n",
       " 'level',\n",
       " 'sinc',\n",
       " 'last',\n",
       " 'two',\n",
       " 'month']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "stem_out=[stemmer.stem(words) for words in words]\n",
    "\n",
    "stem_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adc9459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e162788a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'self',\n",
       " 'doni',\n",
       " 'prathamesh',\n",
       " 'pune',\n",
       " 'good',\n",
       " 'programming',\n",
       " 'expert',\n",
       " 'level',\n",
       " 'since',\n",
       " 'last',\n",
       " 'two',\n",
       " 'month']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lemmetizer=WordNetLemmatizer()\n",
    "lemmat_out=[Lemmetizer.lemmatize(words) for words in words]\n",
    "\n",
    "lemmat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3529d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56ff80bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('my', 'PRP$'),\n",
       " ('self', 'NN'),\n",
       " ('doni', 'NN'),\n",
       " ('prathamesh', 'JJ'),\n",
       " ('pune', 'NN'),\n",
       " ('good', 'JJ'),\n",
       " ('programming', 'NN'),\n",
       " ('expert', 'NN'),\n",
       " ('level', 'NN'),\n",
       " ('since', 'IN'),\n",
       " ('last', 'JJ'),\n",
       " ('two', 'CD'),\n",
       " ('months', 'NNS')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging=pos_tag(words)\n",
    "tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5142a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['the cat see the mouse',\n",
    "      'the house has a tiny little mouse',\n",
    "       'the mouse ran away from the house',\n",
    "        'the cat finally ate the mouse',\n",
    "       'the end of the mouse story'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "777a94d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ate</th>\n",
       "      <th>away</th>\n",
       "      <th>cat</th>\n",
       "      <th>end</th>\n",
       "      <th>finally</th>\n",
       "      <th>from</th>\n",
       "      <th>has</th>\n",
       "      <th>house</th>\n",
       "      <th>little</th>\n",
       "      <th>mouse</th>\n",
       "      <th>of</th>\n",
       "      <th>ran</th>\n",
       "      <th>see</th>\n",
       "      <th>story</th>\n",
       "      <th>the</th>\n",
       "      <th>tiny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ate  away  cat  end  finally  from  has  house  little  mouse  of  ran   \n",
       "0    0     0    1    0        0     0    0      0       0      1   0    0  \\\n",
       "1    0     0    0    0        0     0    1      1       1      1   0    0   \n",
       "2    0     1    0    0        0     1    0      1       0      1   0    1   \n",
       "3    1     0    1    0        1     0    0      0       0      1   0    0   \n",
       "4    0     0    0    1        0     0    0      0       0      1   1    0   \n",
       "\n",
       "   see  story  the  tiny  \n",
       "0    1      0    2     0  \n",
       "1    0      0    1     1  \n",
       "2    0      0    2     0  \n",
       "3    0      0    2     0  \n",
       "4    0      1    2     0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "\n",
    "cv=CountVectorizer()\n",
    "vector_word=cv.fit_transform(docs)\n",
    "\n",
    "tf=pd.DataFrame(vector_word.toarray(),columns=cv.get_feature_names())\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40609251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ate</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>away</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>end</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finally</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>from</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>has</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>house</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>little</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mouse</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>of</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ran</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>see</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>story</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tiny</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features       IDF\n",
       "0       ate  2.098612\n",
       "1      away  2.098612\n",
       "2       cat  1.693147\n",
       "3       end  2.098612\n",
       "4   finally  2.098612\n",
       "5      from  2.098612\n",
       "6       has  2.098612\n",
       "7     house  1.693147\n",
       "8    little  2.098612\n",
       "9     mouse  1.000000\n",
       "10       of  2.098612\n",
       "11      ran  2.098612\n",
       "12      see  2.098612\n",
       "13    story  2.098612\n",
       "14      the  1.000000\n",
       "15     tiny  2.098612"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf=TfidfTransformer()\n",
    "\n",
    "X=tfidf.fit_transform(vector_word.toarray())\n",
    "\n",
    "idf=pd.DataFrame({\"Features\":cv.get_feature_names(),\"IDF\":tfidf.idf_})\n",
    "\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665957c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4359a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=pd.DataFrame(X.toarray(),c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552cbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb1991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26373e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8cd8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38aeff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa86fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ece4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c01cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d58c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d962b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b9655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c2c3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d55987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318db35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f559003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b01a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186ae515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4e548e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e8cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e6026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d14ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a9b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d804ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([df,df1],axis=\"columns\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
